{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ8sPJXvoYTf",
        "outputId": "b7a81b4f-1e5d-4dda-d8fb-9917330ee816"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/LLM/Gen_AI')"
      ],
      "metadata": {
        "id": "mvsCPsLBopYA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yVE30EMThWPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a2d7a1-9fa5-48ca-b516-8c7467f21913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/542.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/542.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m358.4/542.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# \"\"\"!pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install tokenizer\n",
        "# !pip install seqeval\n",
        "# \"\"\"\n",
        "# #either you can use above statement or use single command\n",
        "# # Install\n",
        "!pip install transformers datasets tokenizers seqeval -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLDEFgpk-WI",
        "outputId": "4ce2cc4b-0662-425c-f8f8-700b29f2ba16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IkF5laABlwL9"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSMUGPtnkH1",
        "outputId": "8fd2f523-20e0-451a-f95c-19f6e8896dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "conll2003 = datasets.load_dataset(\"conll2003\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmNlLA8SofOf",
        "outputId": "82837d7a-ecb3-4852-c152-9756b9168350"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "conll2003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q5bDAubptQi",
        "outputId": "68280534-7e6b-479a-b15c-3e342248a087"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "    num_rows: 14041\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "conll2003[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a39FQ94Kp0QG",
        "outputId": "fe18ab25-a0fc-472a-c50e-1e9b1cedc43e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "conll2003[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR8tTo6iqa4o",
        "outputId": "fb882d41-44e8-48ad-d10c-628ebbe2b99e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "    num_rows: 14041\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "conll2003[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I75eeKXcp4qx",
        "outputId": "7d4bced4-cf7f-4733-9e1b-cc9e7e2456be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"].features['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "WEwLrLrxqQRC",
        "outputId": "3dd24556-7812-409f-d3cf-e22ca482de27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "conll2003[\"train\"].description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HmxRWM5Orijk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6236a36a-c54f-4d5e-e699-2a926910cbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StnO3YtTxxCv",
        "outputId": "a1abbf1e-8f76-4fa3-d3a4-4928718745d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ5jjxtWx0HN",
        "outputId": "0d0cb824-0ec1-4cfb-ec99-08ed1bed8a9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"].features['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iyitpGdMyF0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40efcceb-6c60-4757-d342-eb0a20b749c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '10',\n",
              " 'tokens': ['Spanish',\n",
              "  'Farm',\n",
              "  'Minister',\n",
              "  'Loyola',\n",
              "  'de',\n",
              "  'Palacio',\n",
              "  'had',\n",
              "  'earlier',\n",
              "  'accused',\n",
              "  'Fischler',\n",
              "  'at',\n",
              "  'an',\n",
              "  'EU',\n",
              "  'farm',\n",
              "  'ministers',\n",
              "  \"'\",\n",
              "  'meeting',\n",
              "  'of',\n",
              "  'causing',\n",
              "  'unjustified',\n",
              "  'alarm',\n",
              "  'through',\n",
              "  '\"',\n",
              "  'dangerous',\n",
              "  'generalisation',\n",
              "  '.',\n",
              "  '\"'],\n",
              " 'pos_tags': [22,\n",
              "  22,\n",
              "  22,\n",
              "  22,\n",
              "  22,\n",
              "  22,\n",
              "  38,\n",
              "  31,\n",
              "  40,\n",
              "  22,\n",
              "  15,\n",
              "  12,\n",
              "  16,\n",
              "  21,\n",
              "  24,\n",
              "  27,\n",
              "  21,\n",
              "  15,\n",
              "  39,\n",
              "  16,\n",
              "  21,\n",
              "  15,\n",
              "  0,\n",
              "  16,\n",
              "  21,\n",
              "  7,\n",
              "  0],\n",
              " 'chunk_tags': [11,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  21,\n",
              "  22,\n",
              "  22,\n",
              "  11,\n",
              "  13,\n",
              "  11,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  21,\n",
              "  1,\n",
              "  11,\n",
              "  13,\n",
              "  0,\n",
              "  11,\n",
              "  12,\n",
              "  0,\n",
              "  0],\n",
              " 'ner_tags': [7,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "example_text = conll2003['train'][10]\n",
        "example_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4rJLE_WykFj",
        "outputId": "6eada64f-aa34-454d-abde-c8eee814c5a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Spanish',\n",
              " 'Farm',\n",
              " 'Minister',\n",
              " 'Loyola',\n",
              " 'de',\n",
              " 'Palacio',\n",
              " 'had',\n",
              " 'earlier',\n",
              " 'accused',\n",
              " 'Fischler',\n",
              " 'at',\n",
              " 'an',\n",
              " 'EU',\n",
              " 'farm',\n",
              " 'ministers',\n",
              " \"'\",\n",
              " 'meeting',\n",
              " 'of',\n",
              " 'causing',\n",
              " 'unjustified',\n",
              " 'alarm',\n",
              " 'through',\n",
              " '\"',\n",
              " 'dangerous',\n",
              " 'generalisation',\n",
              " '.',\n",
              " '\"']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "example_text[\"tokens\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "te0BldE9yWXC"
      },
      "outputs": [],
      "source": [
        "tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of token_type_ids:\n",
        "\n",
        "Purpose: This list helps some NLP models, particularly BERT, understand if there are multiple pieces of text (sentences) being provided as input.<br>\n",
        "Values: Each element in the list corresponds to a word (token) in the input_ids list. The value can be either 0 or 1.<br>\n",
        "Interpretation in your case: Since all the values in token_type_ids are 0, the model understands that all the tokens (words) belong to the same sentence. There's no distinction between separate pieces of text.<br>\n",
        "\n",
        "Points to note:<br>\n",
        "Not all NLP models require token_type_ids. Some models can infer sentence boundaries from other information like punctuation or special tokens.<br>\n",
        "The use of token_type_ids can become relevant when dealing with tasks involving two or more sentences, like question answering or sentiment analysis of a conversation between two people. In such cases, you would see a combination of 0s and 1s in the token_type_ids list to differentiate between the sentences."
      ],
      "metadata": {
        "id": "RbFhQHHEyeSO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6JomFjpk-XP",
        "outputId": "e6ae99d6-4141-43c1-ae39-4db685d97868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 3009, 3888, 2704, 21580, 2139, 14412, 21361, 2018, 3041, 5496, 27424, 2818, 3917, 2012, 2019, 7327, 3888, 7767, 1005, 3116, 1997, 4786, 4895, 29427, 7810, 8598, 2083, 1000, 4795, 2236, 6648, 1012, 1000, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "tokenized_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBePj4qVypbq",
        "outputId": "ed2caf2d-f146-424d-8f32-8d8cf2206b81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 3009,\n",
              " 3888,\n",
              " 2704,\n",
              " 21580,\n",
              " 2139,\n",
              " 14412,\n",
              " 21361,\n",
              " 2018,\n",
              " 3041,\n",
              " 5496,\n",
              " 27424,\n",
              " 2818,\n",
              " 3917,\n",
              " 2012,\n",
              " 2019,\n",
              " 7327,\n",
              " 3888,\n",
              " 7767,\n",
              " 1005,\n",
              " 3116,\n",
              " 1997,\n",
              " 4786,\n",
              " 4895,\n",
              " 29427,\n",
              " 7810,\n",
              " 8598,\n",
              " 2083,\n",
              " 1000,\n",
              " 4795,\n",
              " 2236,\n",
              " 6648,\n",
              " 1012,\n",
              " 1000,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenized_input[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x394QYEBy3P-",
        "outputId": "67e0acb4-4a7e-4863-d893-d6e7edcb4129"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 3009, 3888, 2704, 21580, 2139, 14412, 21361, 2018, 3041, 5496, 27424, 2818, 3917, 2012, 2019, 7327, 3888, 7767, 1005, 3116, 1997, 4786, 4895, 29427, 7810, 8598, 2083, 1000, 4795, 2236, 6648, 1012, 1000, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tokenized_input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer.convert_ids_to_tokens function:\n",
        "\n",
        "This function is part of libraries like Transformers used for Natural Language Processing (NLP) tasks.<br>\n",
        "It takes a list of integer IDs (typically from the input_ids field after tokenization) as input.<br>\n",
        "Its purpose is to convert these IDs back into the corresponding tokens (words) in the original vocabulary used by the tokenizer."
      ],
      "metadata": {
        "id": "nCTeSrPm9_ZE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sbCZhDpEyq1A"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAUZb2t3y9Lp",
        "outputId": "33ecfe86-d003-490a-b4c3-fc913dddb41f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'spanish',\n",
              " 'farm',\n",
              " 'minister',\n",
              " 'loyola',\n",
              " 'de',\n",
              " 'pal',\n",
              " '##acio',\n",
              " 'had',\n",
              " 'earlier',\n",
              " 'accused',\n",
              " 'fis',\n",
              " '##ch',\n",
              " '##ler',\n",
              " 'at',\n",
              " 'an',\n",
              " 'eu',\n",
              " 'farm',\n",
              " 'ministers',\n",
              " \"'\",\n",
              " 'meeting',\n",
              " 'of',\n",
              " 'causing',\n",
              " 'un',\n",
              " '##just',\n",
              " '##ified',\n",
              " 'alarm',\n",
              " 'through',\n",
              " '\"',\n",
              " 'dangerous',\n",
              " 'general',\n",
              " '##isation',\n",
              " '.',\n",
              " '\"',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyOSDn4py-L0",
        "outputId": "6bc3a0ab-e397-4c08-fef2-6fb4ff983ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[None, 0, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 20, 21, 22, 23, 24, 24, 25, 26, None]\n"
          ]
        }
      ],
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "\n",
        "print(word_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfqg5K6z0sPD",
        "outputId": "43a5137b-b06b-4b08-e3d4-f87dbcca7bac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_text[\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N02NWExd0zrn",
        "outputId": "e6ed5460-73cc-4a80-df10-892934f2f7bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 3\n",
            "1 0\n",
            "2 7\n",
            "3 0\n",
            "4 0\n",
            "5 0\n",
            "6 7\n",
            "7 0\n",
            "8 0\n"
          ]
        }
      ],
      "source": [
        "for i, label in enumerate(example_text[\"ner_tags\"]):\n",
        "  print(i,label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "label_all_tokens=True (default):\n",
        "\n",
        "In this case, the code assigns the NER label to all tokens, including those that might be subwords created during tokenization.<br>\n",
        "This means that even if a single word is split into multiple subwords, each subword will inherit the NER label of the entire word.\n",
        "label_all_tokens=False:\n",
        "\n",
        "When set to False, the code only assigns the NER label to the first subword of a word that gets split during tokenization.<br>\n",
        "Subsequent subwords representing the same word will be assigned a label of -100, essentially ignoring them in the loss function during training.\n",
        "\n",
        "Why the difference?\n",
        "\n",
        "Some tokenizers, like Byte Pair Encoding (BPE), might break down words into smaller subword units.<br>\n",
        "Assigning labels to every subword can be redundant, especially if the subword doesn't carry much meaning on its own.<br>\n",
        "By assigning the label only to the first subword and ignoring the rest (with -100), the model focuses on the most relevant parts of the word for NER tasks.<br>\n",
        "Example:\n",
        "\n",
        "Consider the word \"running\" which might be split into subwords \"run\" and \"ning\" by the tokenizer.\n",
        "\n",
        "With label_all_tokens=True, both \"run\" and \"ning\" would get the same NER label assigned (assuming \"running\" has a label).<br>\n",
        "With label_all_tokens=False, only \"run\" would get the NER label, and \"ning\" would be assigned -100, effectively ignoring it during training.<br>\n",
        "Choosing the right setting:\n",
        "\n",
        "If your task focuses on recognizing named entities at the word level, label_all_tokens=False might be more efficient.<br>\n",
        "If you need to capture information within subwords (less common), label_all_tokens=True might be necessary.<br>\n",
        "The best setting depends on your specific NER task and the tokenizer you're using"
      ],
      "metadata": {
        "id": "PAy1OovWAgKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch_index argument in the word_ids method is used because the tokenize_and_align_labels function is likely designed to handle multiple examples (sentences) at once, forming a batch.\n",
        "\n",
        "Here's a breakdown of why batch_index is important:\n",
        "\n",
        "Batch processing: NLP libraries like Transformers often allow processing multiple text examples in a single call for efficiency. This creates a batch of data.<br>\n",
        "tokenized_inputs: This variable likely holds the results of tokenization for the entire batch of examples. It might be a dictionary containing information like token IDs, attention masks, etc., for each example.<br>\n",
        "word_ids: This method retrieves the word IDs specifically for a particular example within the batch. The batch_index argument tells the function which example's word IDs you want to access.<br>\n",
        "Example:\n",
        "\n",
        "Imagine you have two sentences (examples) and you tokenize them together:\n",
        "\n",
        "Sentence 1: \"The quick brown fox jumps over the lazy dog\"<br>\n",
        "Sentence 2: \"This is a test sentence\"<br>\n",
        "After tokenization, tokenized_inputs might be a dictionary containing token IDs and other information for both sentences.\n",
        "\n",
        "When you use word_ids(batch_index=0), you're accessing the word IDs for the first sentence (batch index 0) within tokenized_inputs. Similarly, word_ids(batch_index=1) would retrieve the word IDs for the second sentence.\n",
        "\n",
        "In essence, batch_index allows you to extract information (like word IDs) for a specific example within a batch of processed text data."
      ],
      "metadata": {
        "id": "uh-JQzNUEs5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3ubJqVH1zN9k"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=False):\n",
        "\n",
        "    #tokeinze ids\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)#\n",
        "        # word_ids() => Return a list mapping the tokens\n",
        "        # to their actual word in the initial sentence.\n",
        "        # It Returns a list indicating the word corresponding to each token.\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        # Special tokens like `` and `<\\s>` are originally mapped to None\n",
        "        # We need to set the label to -100 so they are automatically ignored in the loss function.\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # set –100 as the label for these special tokens\n",
        "                label_ids.append(-100)\n",
        "\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # if current word_idx is != prev then its the most regular case\n",
        "                # and add the corresponding token\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                #print(label)\n",
        "                # to take care of sub-words which have the same word_idx\n",
        "                # set -100 as well for them, but only if label_all_tokens == False\n",
        "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "                # mask the subword representations after the first subword\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlqlXdpzk-Xu",
        "outputId": "7de001b4-cd6c-4a93-e1f8-78d356d45103"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': ['10'],\n",
              " 'tokens': [['Spanish',\n",
              "   'Farm',\n",
              "   'Minister',\n",
              "   'Loyola',\n",
              "   'de',\n",
              "   'Palacio',\n",
              "   'had',\n",
              "   'earlier',\n",
              "   'accused',\n",
              "   'Fischler',\n",
              "   'at',\n",
              "   'an',\n",
              "   'EU',\n",
              "   'farm',\n",
              "   'ministers',\n",
              "   \"'\",\n",
              "   'meeting',\n",
              "   'of',\n",
              "   'causing',\n",
              "   'unjustified',\n",
              "   'alarm',\n",
              "   'through',\n",
              "   '\"',\n",
              "   'dangerous',\n",
              "   'generalisation',\n",
              "   '.',\n",
              "   '\"']],\n",
              " 'pos_tags': [[22,\n",
              "   22,\n",
              "   22,\n",
              "   22,\n",
              "   22,\n",
              "   22,\n",
              "   38,\n",
              "   31,\n",
              "   40,\n",
              "   22,\n",
              "   15,\n",
              "   12,\n",
              "   16,\n",
              "   21,\n",
              "   24,\n",
              "   27,\n",
              "   21,\n",
              "   15,\n",
              "   39,\n",
              "   16,\n",
              "   21,\n",
              "   15,\n",
              "   0,\n",
              "   16,\n",
              "   21,\n",
              "   7,\n",
              "   0]],\n",
              " 'chunk_tags': [[11,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   21,\n",
              "   22,\n",
              "   22,\n",
              "   11,\n",
              "   13,\n",
              "   11,\n",
              "   12,\n",
              "   12,\n",
              "   12,\n",
              "   11,\n",
              "   12,\n",
              "   13,\n",
              "   21,\n",
              "   1,\n",
              "   11,\n",
              "   13,\n",
              "   0,\n",
              "   11,\n",
              "   12,\n",
              "   0,\n",
              "   0]],\n",
              " 'ner_tags': [[7,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   2,\n",
              "   2,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   1,\n",
              "   0,\n",
              "   0,\n",
              "   3,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0]]}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"][10:11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtHHw9R2k-Xv"
      },
      "outputs": [],
      "source": [
        "q=tokenize_and_align_labels(conll2003[\"train\"][10:11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIL87YYmk-Xw",
        "outputId": "205dff5a-3ead-437e-c0eb-6ce43680fcd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 3009, 3888, 2704, 21580, 2139, 14412, 21361, 2018, 3041, 5496, 27424, 2818, 3917, 2012, 2019, 7327, 3888, 7767, 1005, 3116, 1997, 4786, 4895, 29427, 7810, 8598, 2083, 1000, 4795, 2236, 6648, 1012, 1000, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 7, 0, 0, 1, 2, 2, 2, 0, 0, 0, 1, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9XvqAV2k-Xx",
        "outputId": "578a60da-d9bf-4238-9411-9e278e055497"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[5,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  3,\n",
              "  4,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  5,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0]]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conll2003[\"train\"][4:5]['ner_tags']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CtIPEziA1szx"
      },
      "outputs": [],
      "source": [
        "q=tokenize_and_align_labels(conll2003[\"train\"][4:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MNRfU7Mk-X0",
        "outputId": "73e08f7c-b311-40a4-d5a4-afd6e6b6035e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHM4esZX2COy",
        "outputId": "9c1d2c30-b0d7-4d80-9ddd-f0d4735c0ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "germany_________________________________ 5\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "representative__________________________ 0\n",
            "to______________________________________ 0\n",
            "the_____________________________________ 0\n",
            "european________________________________ 3\n",
            "union___________________________________ 4\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "veterinary______________________________ 0\n",
            "committee_______________________________ 0\n",
            "werner__________________________________ 1\n",
            "z_______________________________________ 2\n",
            "##wing__________________________________ 2\n",
            "##mann__________________________________ 2\n",
            "said____________________________________ 0\n",
            "on______________________________________ 0\n",
            "wednesday_______________________________ 0\n",
            "consumers_______________________________ 0\n",
            "should__________________________________ 0\n",
            "buy_____________________________________ 0\n",
            "sheep___________________________________ 0\n",
            "##me____________________________________ 0\n",
            "##at____________________________________ 0\n",
            "from____________________________________ 0\n",
            "countries_______________________________ 0\n",
            "other___________________________________ 0\n",
            "than____________________________________ 0\n",
            "britain_________________________________ 5\n",
            "until___________________________________ 0\n",
            "the_____________________________________ 0\n",
            "scientific______________________________ 0\n",
            "advice__________________________________ 0\n",
            "was_____________________________________ 0\n",
            "clearer_________________________________ 0\n",
            "._______________________________________ 0\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ],
      "source": [
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]):\n",
        "    print(f\"{token:_<40} {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-fEdnsKH2LyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "74858d266f35483280abbbb472fc3b96",
            "3a55e36b7b5347c38a966508b676226b",
            "788a0231eeaf401a8e05fa9f7df968dc",
            "6c4bf16cbd3c465a82d16ed560765ab5",
            "c4bdc1375b424f738724580b742237c2",
            "ce4eebbf1801467fb2c7b6ebb5b9c58f",
            "4ae539a134ba481d8c29d05047b0f9a9",
            "76d5479493fa4d038486bd102529cfdf",
            "11e5960835884db1b69fc8bc0bc8ee32",
            "5b4ce857677b45309bbdb1bedbf2ab0c",
            "448c995c643e425f9f1b993f913b14bb"
          ]
        },
        "outputId": "de1e3809-b8ae-4ba8-e114-3409fe6644c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74858d266f35483280abbbb472fc3b96"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Applying on entire data\n",
        "tokenized_datasets=conll2003.map(tokenize_and_align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNpnZMfF29im",
        "outputId": "6131ee95-b3be-4e29-cbe9-b297f804889d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 14041\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "tokenized_datasets[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-eRkzw53Eoh",
        "outputId": "855b8449-968d-4e66-b805-0d8634168186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\",num_labels=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lMiMj7mK3x0u"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "data_collator=DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pbVuoJjP4CUt"
      },
      "outputs": [],
      "source": [
        "args = TrainingArguments(\n",
        "\"test-ner\",\n",
        "evaluation_strategy = \"epoch\",\n",
        "learning_rate=2e-5,\n",
        "per_device_train_batch_size=16,\n",
        "per_device_eval_batch_size=16,\n",
        "num_train_epochs=10,\n",
        "weight_decay=0.01\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KZh154g24cDG"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Batching for Efficient Training:\n",
        "\n",
        "Deep learning models like Transformers typically train on batches of data rather than individual examples. This improves training speed and memory usage on your hardware.<br>\n",
        "Data collators act as the bridge between your raw data and the training process. They take care of assembling individual data points (e.g., tokenized sentences, labels) into these training batches.\n",
        "2. Data Processing and Alignment:\n",
        "\n",
        "Data collators can perform various processing steps on your data before batching. This might include:<br>\n",
        "Padding: Ensuring all elements in a batch have the same length. Models that process sequences require fixed input sizes. Padding achieves this by adding special tokens (e.g., \"[PAD]\") to shorter sequences.<br>\n",
        "Truncation: Limiting the length of overly long sequences to fit training constraints.<br>\n",
        "Masking: Techniques like random masking (used in language modeling) can be applied by data collators.<br>\n",
        "3. Handling Different Data Formats:\n",
        "\n",
        "NLP tasks often involve different data formats. Data collators can handle this variety. They allow you to specify how various elements (tokens, labels, etc.) in your data should be combined into a training batch."
      ],
      "metadata": {
        "id": "yxAXC2TUV4LQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OVoXke9U4jLA"
      },
      "outputs": [],
      "source": [
        "# Trainer(\n",
        "#    model,\n",
        "#    args,\n",
        "#    train_dataset=tokenized_datasets[\"train\"],\n",
        "#    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "#    data_collator=data_collator,\n",
        "#    tokenizer=tokenizer,\n",
        "#    compute_metrics=compute_metrics\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179,
          "referenced_widgets": [
            "2ec9036bf5bd4ecfae252d066304637c",
            "86ae7bcd46e646d7a8bf3ba47800ddcf",
            "b2a08bc60b4a4e3f95dafa12ca21b14a",
            "6b764d282b9b4e9f9dbdea0d62d4d89e",
            "d0587a67f7df48fa89244aec7a595d55",
            "b9f6c2fd7ce74b72a8d6289af280d4ff",
            "34fdef286e7f43b1a5475a73e7ed2e8e",
            "52dc21c41aae41deb07f3f56b8b929f3",
            "1060dcc5793545138d24ebafb04440f0",
            "7d440c140321433c94d6bd8668f84eb2",
            "c893b75b32444f559a62f271156c2d0c"
          ]
        },
        "id": "eRDqIBmz6F1z",
        "outputId": "957cc381-2d9d-49fd-ea35-cd75dac1b0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-453905903fc4>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric=datasets.load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec9036bf5bd4ecfae252d066304637c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "metric=datasets.load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ePYHr5fe0Nd",
        "outputId": "fe2f1c00-522b-4ea1-dc94-dc01236598c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VftjL1R05U-E"
      },
      "outputs": [],
      "source": [
        "example=conll2003['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lneowFDYWX6s",
        "outputId": "b9cf2dd1-e7e4-4b1c-d09e-c5ebd8977a8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '0',\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.'],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltu1T51R6R06",
        "outputId": "62e7cccc-e962-4e44-b873-0c62da06031c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
        "\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Gni6IvWC6XTd",
        "outputId": "7601b7a3-54c5-4c22-80b7-7115e6d8a9d5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'example' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b46684c75d67>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
          ]
        }
      ],
      "source": [
        "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD-rI-s-6jgU",
        "outputId": "5274bd75-0421-4ee1-a7ab-7593217f49d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "metric.compute(predictions=[labels],references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value=0"
      ],
      "metadata": {
        "id": "fvAIvIvNhlPZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "39jv0s-a7Kte"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    pred_logits, labels = eval_preds\n",
        "\n",
        "    pred_logits = np.argmax(pred_logits, axis=2)\n",
        "\n",
        "    # the logits and the probabilities are in the same order,\n",
        "    # so we don’t need to apply the softmax\n",
        "\n",
        "    # We remove all the values where the label is -100\n",
        "    predictions = [\n",
        "        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(pred_logits, labels)\n",
        "    ]\n",
        "\n",
        "    true_labels = [\n",
        "      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n",
        "       for prediction, label in zip(pred_logits, labels)\n",
        "   ]\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "\n",
        "    return {\n",
        "          \"precision\": results[\"overall_precision\"],\n",
        "          \"recall\": results[\"overall_recall\"],\n",
        "          \"f1\": results[\"overall_f1\"],\n",
        "          \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uwVulRS-8JdG"
      },
      "outputs": [],
      "source": [
        "data_collator=DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2XSqn0Sb7qtu"
      },
      "outputs": [],
      "source": [
        "trainer=Trainer(\n",
        "   model,\n",
        "   args,\n",
        "   train_dataset=tokenized_datasets[\"test\"],\n",
        "   eval_dataset=tokenized_datasets[\"validation\"],\n",
        "   data_collator=data_collator,\n",
        "   tokenizer=tokenizer,\n",
        "   compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "MwRQ2KPr8ThI",
        "outputId": "d707a83c-b2c5-40b2-ca4a-39e23aeb9c30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2160' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2160/2160 08:03, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.134518</td>\n",
              "      <td>0.901658</td>\n",
              "      <td>0.915012</td>\n",
              "      <td>0.908286</td>\n",
              "      <td>0.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.130071</td>\n",
              "      <td>0.892074</td>\n",
              "      <td>0.911141</td>\n",
              "      <td>0.901507</td>\n",
              "      <td>0.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.131711</td>\n",
              "      <td>0.906953</td>\n",
              "      <td>0.908785</td>\n",
              "      <td>0.907868</td>\n",
              "      <td>0.981309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.003800</td>\n",
              "      <td>0.136192</td>\n",
              "      <td>0.903811</td>\n",
              "      <td>0.914002</td>\n",
              "      <td>0.908878</td>\n",
              "      <td>0.981329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.131922</td>\n",
              "      <td>0.897151</td>\n",
              "      <td>0.911646</td>\n",
              "      <td>0.904341</td>\n",
              "      <td>0.981114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.135502</td>\n",
              "      <td>0.910951</td>\n",
              "      <td>0.914170</td>\n",
              "      <td>0.912558</td>\n",
              "      <td>0.981757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.134559</td>\n",
              "      <td>0.899309</td>\n",
              "      <td>0.919892</td>\n",
              "      <td>0.909484</td>\n",
              "      <td>0.981348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.136444</td>\n",
              "      <td>0.898908</td>\n",
              "      <td>0.914339</td>\n",
              "      <td>0.906558</td>\n",
              "      <td>0.981426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.142117</td>\n",
              "      <td>0.905906</td>\n",
              "      <td>0.913834</td>\n",
              "      <td>0.909853</td>\n",
              "      <td>0.981699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.140406</td>\n",
              "      <td>0.905563</td>\n",
              "      <td>0.915012</td>\n",
              "      <td>0.910263</td>\n",
              "      <td>0.981893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2160, training_loss=0.002696328810243695, metrics={'train_runtime': 483.7322, 'train_samples_per_second': 71.382, 'train_steps_per_second': 4.465, 'total_flos': 848476607721174.0, 'train_loss': 0.002696328810243695, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6vuTSmBu8V6d"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"ner_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0tA7MCe9MVs",
        "outputId": "d753c3a0-6c04-44d6-b894-918ec7fdef2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A57V_ELI9XVA",
        "outputId": "607c8d47-2e7d-46ca-c264-428ca41babcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "O54dK99e-D4u"
      },
      "outputs": [],
      "source": [
        "id2label = {\n",
        "    str(i): label for i,label in enumerate(label_list)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_sNX73b-HT3",
        "outputId": "40591e1e-a97b-4623-9058-a95a0897ba12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 'O',\n",
              " '1': 'B-PER',\n",
              " '2': 'I-PER',\n",
              " '3': 'B-ORG',\n",
              " '4': 'I-ORG',\n",
              " '5': 'B-LOC',\n",
              " '6': 'I-LOC',\n",
              " '7': 'B-MISC',\n",
              " '8': 'I-MISC'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "8c6J4gAD-JnO"
      },
      "outputs": [],
      "source": [
        "label2id = {\n",
        "    label: str(i) for i,label in enumerate(label_list)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAbha6hd-MHA",
        "outputId": "7b9de363-2e56-496f-ba3d-2abc58b26148"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': '0',\n",
              " 'B-PER': '1',\n",
              " 'I-PER': '2',\n",
              " 'B-ORG': '3',\n",
              " 'I-ORG': '4',\n",
              " 'B-LOC': '5',\n",
              " 'I-LOC': '6',\n",
              " 'B-MISC': '7',\n",
              " 'I-MISC': '8'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "V0LfS320-Pfa"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hC0wBuQb-Rgr"
      },
      "outputs": [],
      "source": [
        "config=json.load(open(\"/content/drive/MyDrive/LLM/Gen_AI/ner_model/config.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6YoLMEq-g85",
        "outputId": "3b621b08-e9ad-410c-d47e-d10b9fbd58ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_name_or_path': 'bert-base-uncased',\n",
              " 'architectures': ['BertForTokenClassification'],\n",
              " 'attention_probs_dropout_prob': 0.1,\n",
              " 'classifier_dropout': None,\n",
              " 'gradient_checkpointing': False,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'id2label': {'0': 'LABEL_0',\n",
              "  '1': 'LABEL_1',\n",
              "  '2': 'LABEL_2',\n",
              "  '3': 'LABEL_3',\n",
              "  '4': 'LABEL_4',\n",
              "  '5': 'LABEL_5',\n",
              "  '6': 'LABEL_6',\n",
              "  '7': 'LABEL_7',\n",
              "  '8': 'LABEL_8'},\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'label2id': {'LABEL_0': 0,\n",
              "  'LABEL_1': 1,\n",
              "  'LABEL_2': 2,\n",
              "  'LABEL_3': 3,\n",
              "  'LABEL_4': 4,\n",
              "  'LABEL_5': 5,\n",
              "  'LABEL_6': 6,\n",
              "  'LABEL_7': 7,\n",
              "  'LABEL_8': 8},\n",
              " 'layer_norm_eps': 1e-12,\n",
              " 'max_position_embeddings': 512,\n",
              " 'model_type': 'bert',\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'pad_token_id': 0,\n",
              " 'position_embedding_type': 'absolute',\n",
              " 'torch_dtype': 'float32',\n",
              " 'transformers_version': '4.40.2',\n",
              " 'type_vocab_size': 2,\n",
              " 'use_cache': True,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oqWpyHoh-cKS"
      },
      "outputs": [],
      "source": [
        "config[\"id2label\"] = id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TBoL387O-cNX"
      },
      "outputs": [],
      "source": [
        "config[\"label2id\"] = label2id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmM9eLRklWaQ",
        "outputId": "b6f9e201-c1f9-499b-e0ec-a782fde15523"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_name_or_path': 'bert-base-uncased',\n",
              " 'architectures': ['BertForTokenClassification'],\n",
              " 'attention_probs_dropout_prob': 0.1,\n",
              " 'classifier_dropout': None,\n",
              " 'gradient_checkpointing': False,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'id2label': {'0': 'O',\n",
              "  '1': 'B-PER',\n",
              "  '2': 'I-PER',\n",
              "  '3': 'B-ORG',\n",
              "  '4': 'I-ORG',\n",
              "  '5': 'B-LOC',\n",
              "  '6': 'I-LOC',\n",
              "  '7': 'B-MISC',\n",
              "  '8': 'I-MISC'},\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'label2id': {'O': '0',\n",
              "  'B-PER': '1',\n",
              "  'I-PER': '2',\n",
              "  'B-ORG': '3',\n",
              "  'I-ORG': '4',\n",
              "  'B-LOC': '5',\n",
              "  'I-LOC': '6',\n",
              "  'B-MISC': '7',\n",
              "  'I-MISC': '8'},\n",
              " 'layer_norm_eps': 1e-12,\n",
              " 'max_position_embeddings': 512,\n",
              " 'model_type': 'bert',\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'pad_token_id': 0,\n",
              " 'position_embedding_type': 'absolute',\n",
              " 'torch_dtype': 'float32',\n",
              " 'transformers_version': '4.40.2',\n",
              " 'type_vocab_size': 2,\n",
              " 'use_cache': True,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "nhT4qrDP-cS2"
      },
      "outputs": [],
      "source": [
        "json.dump(config,open(\"/content/drive/MyDrive/LLM/Gen_AI/ner_model/config.json\",\"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XZn7yPWllxv",
        "outputId": "92295296-88d7-454a-8f46-54a61b46dc5c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface_transformer.ipynb  \u001b[0m\u001b[01;34mner_model\u001b[0m/  \u001b[01;34mtest-ner\u001b[0m/  \u001b[01;34mtokenizer\u001b[0m/  \u001b[01;34mtrain-ner\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "U1oEoLWS-cUo"
      },
      "outputs": [],
      "source": [
        "model_fine_tuned=AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko-y7l0C_F73",
        "outputId": "f01b63e0-2ecb-4191-aa94-dcee7a87a29d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model_fine_tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQLAZsxW9jT1"
      },
      "source": [
        "# transformer pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Ay6rKFif9j67"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "d7kMV1wQ9na-"
      },
      "outputs": [],
      "source": [
        "nlp_pipeline=pipeline(\"ner\",model=model_fine_tuned,tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoqS99LO_fy3",
        "outputId": "a6237efd-c9ba-417e-dc10-8f35e787f3bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.pipelines.token_classification.TokenClassificationPipeline at 0x78021e612b30>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "nlp_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "tYbT5QgDANPq"
      },
      "outputs": [],
      "source": [
        "example=\"Riad is not able to figure out what to do in his life. He is hopeless. Only One can help him\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UqJsroVAXnH",
        "outputId": "36534dc7-d293-4e75-9e24-fec384566d84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-PER',\n",
              "  'score': 0.9997371,\n",
              "  'index': 1,\n",
              "  'word': 'ri',\n",
              "  'start': 0,\n",
              "  'end': 2},\n",
              " {'entity': 'B-PER',\n",
              "  'score': 0.99857414,\n",
              "  'index': 2,\n",
              "  'word': '##ad',\n",
              "  'start': 2,\n",
              "  'end': 4}]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "nlp_pipeline(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "436NtdA-ArZZ"
      },
      "outputs": [],
      "source": [
        "example=\"Bangladesh is a peaceful country\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkpVk_g3Ab4l",
        "outputId": "7f5ac852-d10a-4987-8f93-665befb21406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-LOC',\n",
              "  'score': 0.99979097,\n",
              "  'index': 1,\n",
              "  'word': 'bangladesh',\n",
              "  'start': 0,\n",
              "  'end': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "nlp_pipeline(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "0h-wIi2hAzSg"
      },
      "outputs": [],
      "source": [
        "example=\"apple launch mobile while eating apple which taste like orange\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_v7CVYsBFoT",
        "outputId": "3f47d5c7-836e-4ded-a849-b6cc227b035e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.98410773,\n",
              "  'index': 1,\n",
              "  'word': 'apple',\n",
              "  'start': 0,\n",
              "  'end': 5},\n",
              " {'entity': 'B-MISC',\n",
              "  'score': 0.98444194,\n",
              "  'index': 6,\n",
              "  'word': 'apple',\n",
              "  'start': 33,\n",
              "  'end': 38}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "nlp_pipeline(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "fscsPD8eBTjT"
      },
      "outputs": [],
      "source": [
        "example=\"apple founder loves eating apple\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXKpdqM4BdL2",
        "outputId": "98c4780a-4232-46a0-d4cc-cd706f5157f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.9994856,\n",
              "  'index': 1,\n",
              "  'word': 'apple',\n",
              "  'start': 0,\n",
              "  'end': 5}]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "nlp_pipeline(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "mpKOmQtMBeVW"
      },
      "outputs": [],
      "source": [
        "example=\"Microsoft Windows created their software by idea that came from the window of the house\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DokBMRjRCAP-",
        "outputId": "ebe0ec1e-1838-4427-9d78-3a93e0b9be98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-ORG',\n",
              "  'score': 0.99952674,\n",
              "  'index': 1,\n",
              "  'word': 'microsoft',\n",
              "  'start': 0,\n",
              "  'end': 9},\n",
              " {'entity': 'I-ORG',\n",
              "  'score': 0.99924207,\n",
              "  'index': 2,\n",
              "  'word': 'windows',\n",
              "  'start': 10,\n",
              "  'end': 17}]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "nlp_pipeline(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5edahwCOCBRo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74858d266f35483280abbbb472fc3b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a55e36b7b5347c38a966508b676226b",
              "IPY_MODEL_788a0231eeaf401a8e05fa9f7df968dc",
              "IPY_MODEL_6c4bf16cbd3c465a82d16ed560765ab5"
            ],
            "layout": "IPY_MODEL_c4bdc1375b424f738724580b742237c2"
          }
        },
        "3a55e36b7b5347c38a966508b676226b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce4eebbf1801467fb2c7b6ebb5b9c58f",
            "placeholder": "​",
            "style": "IPY_MODEL_4ae539a134ba481d8c29d05047b0f9a9",
            "value": "Map: 100%"
          }
        },
        "788a0231eeaf401a8e05fa9f7df968dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d5479493fa4d038486bd102529cfdf",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11e5960835884db1b69fc8bc0bc8ee32",
            "value": 3250
          }
        },
        "6c4bf16cbd3c465a82d16ed560765ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4ce857677b45309bbdb1bedbf2ab0c",
            "placeholder": "​",
            "style": "IPY_MODEL_448c995c643e425f9f1b993f913b14bb",
            "value": " 3250/3250 [00:00&lt;00:00, 4634.16 examples/s]"
          }
        },
        "c4bdc1375b424f738724580b742237c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4eebbf1801467fb2c7b6ebb5b9c58f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae539a134ba481d8c29d05047b0f9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76d5479493fa4d038486bd102529cfdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e5960835884db1b69fc8bc0bc8ee32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b4ce857677b45309bbdb1bedbf2ab0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448c995c643e425f9f1b993f913b14bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec9036bf5bd4ecfae252d066304637c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86ae7bcd46e646d7a8bf3ba47800ddcf",
              "IPY_MODEL_b2a08bc60b4a4e3f95dafa12ca21b14a",
              "IPY_MODEL_6b764d282b9b4e9f9dbdea0d62d4d89e"
            ],
            "layout": "IPY_MODEL_d0587a67f7df48fa89244aec7a595d55"
          }
        },
        "86ae7bcd46e646d7a8bf3ba47800ddcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f6c2fd7ce74b72a8d6289af280d4ff",
            "placeholder": "​",
            "style": "IPY_MODEL_34fdef286e7f43b1a5475a73e7ed2e8e",
            "value": "Downloading builder script: "
          }
        },
        "b2a08bc60b4a4e3f95dafa12ca21b14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52dc21c41aae41deb07f3f56b8b929f3",
            "max": 2471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1060dcc5793545138d24ebafb04440f0",
            "value": 2471
          }
        },
        "6b764d282b9b4e9f9dbdea0d62d4d89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d440c140321433c94d6bd8668f84eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_c893b75b32444f559a62f271156c2d0c",
            "value": " 6.33k/? [00:00&lt;00:00, 299kB/s]"
          }
        },
        "d0587a67f7df48fa89244aec7a595d55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f6c2fd7ce74b72a8d6289af280d4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fdef286e7f43b1a5475a73e7ed2e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52dc21c41aae41deb07f3f56b8b929f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1060dcc5793545138d24ebafb04440f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d440c140321433c94d6bd8668f84eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c893b75b32444f559a62f271156c2d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}